{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward mechanism demo\n",
    "\n",
    "## Imports + Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking.protocol import chunkSynapse\n",
    "import bittensor as bt\n",
    "import requests\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/daniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv tabulate -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API key necessary for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    raise Exception(\"Make sure to set OPENAI_API_KEY in your .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.15556572, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.5013809 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.06271458, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.25069046, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02961776,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netuid = 40\n",
    "network = \"ws://subvortex.info:9944\" # or 'finney'\n",
    "\n",
    "metagraph = bt.metagraph(netuid, network)\n",
    "\n",
    "metagraph.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_name = \"\" # TODO: set wallet name\n",
    "hotkey_name = \"\" # TODO: set hotkey name\n",
    "\n",
    "validator_wallet = bt.wallet(name=wallet_name, hotkey=hotkey_name)\n",
    "validator_dendrite = bt.dendrite(wallet=validator_wallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the top miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking.validator.task_api import generate_synthetic_synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top miner uid: 18\n",
      "Document: ? (also written Tanda Tanya, meaning Question Mark) is a 2011 Indonesian drama film directed by Hanu ...\n",
      "Received 5 chunks from top miner, process time: 0.7442488670349121\n",
      "Chunk 3: The director of Mahaka Pictures, Erick Thohir, sta ...\n"
     ]
    }
   ],
   "source": [
    "page = 33653136 # fixed article id\n",
    "\n",
    "top_miner_uid = metagraph.I.argmax().item()\n",
    "\n",
    "print(f\"Top miner uid: {top_miner_uid}\")\n",
    "\n",
    "top_miner_axon = metagraph.axons[top_miner_uid]\n",
    "\n",
    "# Generate the 'synthetic' query: a featured article from wikipedia.\n",
    "synapse, pageid = generate_synthetic_synapse(None, pageid=page, timeout=20)\n",
    "\n",
    "\n",
    "print(f\"Document: {synapse.document[:100]} ...\")\n",
    "\n",
    "responses: list[chunkSynapse] = validator_dendrite.query(\n",
    "    axons=[top_miner_axon],    \n",
    "    synapse=synapse,\n",
    "    deserialize=False\n",
    ")\n",
    "\n",
    "top_miner_response = responses[0]\n",
    "\n",
    "if not top_miner_response or not top_miner_response.chunks:\n",
    "    raise Exception(\"No response from top miner\")\n",
    "else:\n",
    "    print(f\"Received {len(top_miner_response.chunks)} chunks from top miner, process time: {top_miner_response.dendrite.process_time}\")\n",
    "    print(f\"Chunk 3: {top_miner_response.chunks[2][:50]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def print_extra_info_dict(extra_info_dicts: list[dict], uids: list[int]):\n",
    "    assert len(extra_info_dicts) == len(uids)\n",
    "    \n",
    "    table_data = []\n",
    "    \n",
    "    for extra_info_dict, uid in zip(extra_info_dicts, uids):\n",
    "        table_data.append([\n",
    "            uid,\n",
    "            extra_info_dict.get(\"embedding_reward\", 0),             \n",
    "            extra_info_dict.get(\"size_penalty\", 0),\n",
    "            extra_info_dict.get(\"qty_penalty\", 0),\n",
    "            extra_info_dict.get(\"time_penalty\", 0) \n",
    "        ])\n",
    "        \n",
    "        \n",
    "    table_str = tabulate(table_data, headers=[\"UID\", \"Embedding reward\", \"Size penalty\", \"Quantity penalty\", \"Time Penalty\"], tablefmt=\"grid\")\n",
    "    \n",
    "    print(table_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward the top miners response\n",
    "\n",
    "### Reward Mechanism\n",
    "\n",
    "1) Chunks must not have missing words/messed up ordering\n",
    "    - every continguous three word pair from the source document should be in at least 1 chunk\n",
    "    - every word in a single chunk should be in the same order as in the source document\n",
    "2) Penalties (all penalties are passed into exponential function, and these results are multiplied with \"embedding reward\")\n",
    "    - There is a penalty for chunks that are too long (> `chunk_size` characters)\n",
    "        - Snippet:\n",
    "        ```py\n",
    "        size_penalty += ((chunk_length / chunk_size) - 1) * 10\n",
    "        ```        \n",
    "    - There is a penalty for too many chunks (> `chunk_qty` chunks)\n",
    "        - `chunk_qty` is currently calculated as:\n",
    "        ```py\n",
    "        ceil(ceil(len(document) / chunk_size) * 1.5)\n",
    "        ```        \n",
    "    - There is a time penalty (> `time_soft_max` seconds of process time)\n",
    "        - This is currently `0.75 * synapse.timeout`, `timeout` is default 20 seconds\n",
    "3) Intra-chunk embeddings should ideally have high cosine similarity and inter-chunk embeddings should ideally have low cosine similarity    \n",
    "    - Snippet:\n",
    "    ```py\n",
    "    for i in range(len(testChunks) - 1):\n",
    "        j = i + 1\n",
    "        while j < len(testChunks):\n",
    "            if testChunks[i].sourceChunk == testChunks[j].sourceChunk:\n",
    "                intrachunk_similarities.append(np.dot(np.asarray(embeddings[i]), np.asarray(embeddings[j])))\n",
    "            else:\n",
    "                interchunk_similarities.append(np.dot(np.asarray(embeddings[i]), np.asarray(embeddings[j])))\n",
    "            j += 1            \n",
    "    \n",
    "    reward = (\n",
    "        (np.mean(intrachunk_similarities) if len(intrachunk_similarities) > 0 else 0)\n",
    "        - (np.mean(interchunk_similarities) if len(interchunk_similarities) > 0 else 0)\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - `testChunks` are three sentence chunks formed from each of the returned miner chunks\n",
    "    - `embeddings` are the sampled embeddings of the three sentence chunks, currently created via OpenAI's `text-embedding-ada-002` model\n",
    "    - `reward` is the \"embedding reward\" for the miner\n",
    "    - This reward is exponentiated to ensure it is positive, then the penalties above are applied to get the final reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.013477152416154436\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135683785971434\n",
      "+-------+--------------------+----------------+--------------------+----------------+\n",
      "|   UID |   Embedding reward |   Size penalty |   Quantity penalty |   Time Penalty |\n",
      "+=======+====================+================+====================+================+\n",
      "|    18 |          0.0134772 |              0 |                  0 |              0 |\n",
      "+-------+--------------------+----------------+--------------------+----------------+\n",
      "Top miner reward: 1.0135683785971434\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from chunking.validator.reward import reward\n",
    "\n",
    "bt.debug()\n",
    "\n",
    "print(synapse.chunk_qty)\n",
    "\n",
    "top_miner_reward, extra_info_dict = reward(self=None, document=synapse.document, chunk_size=synapse.chunk_size, chunk_qty=synapse.chunk_qty, response=top_miner_response, override_client=OpenAI(), override_num_embeddings=50, verbose=True)\n",
    "\n",
    "print_extra_info_dict([extra_info_dict], [top_miner_uid])\n",
    "\n",
    "print(f\"Top miner reward: {top_miner_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group tournament ranking\n",
    "\n",
    "Generally, a miner group is queried by a validator at request time. The default group size is `min(metagraph.n, 25)`. The validator will then rank the miners in this group relative to each other based on the incentive mechanism. These local ranks will be then translated into global ranks. Having a lower overall rank is better.\n",
    "\n",
    "Here's an example of querying a group of 4 miners (assuming the `group_size` is 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 miners uids: [ 18 116  13 100]\n",
      "Received 5 chunks from hotkey: 5F2LKK2qEt, process time: 0.7486388683319092\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.01348732129546315\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135786855040612\n",
      "Received 5 chunks from hotkey: 5G7HVdSrYj, process time: 0.7470688819885254\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.01348732129546315\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135786855040612\n",
      "Received 5 chunks from hotkey: 5CdQ2JNXao, process time: 0.5164220333099365\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.01349839362955918\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135899082480306\n",
      "Received 5 chunks from hotkey: 5GFC2SpRcL, process time: 0.7967691421508789\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.013471081159854958\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135622249824199\n",
      "Rewards: [1.01357869 1.01357869 1.01358991 1.01356222]\n",
      "Response ranks: [1. 2. 0. 3.]\n"
     ]
    }
   ],
   "source": [
    "from chunking.validator.reward import rank_responses\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "top_4_miners_uids = metagraph.I.argsort()[-4:][::-1]\n",
    "\n",
    "print(f\"Top 4 miners uids: {top_4_miners_uids}\")\n",
    "\n",
    "axons = [metagraph.axons[uid] for uid in top_4_miners_uids]\n",
    "\n",
    "responses: list[chunkSynapse] = validator_dendrite.query(\n",
    "    axons=axons,\n",
    "    synapse=synapse,\n",
    "    deserialize=False\n",
    ")\n",
    "\n",
    "rewards = []\n",
    "extra_info_dicts = []\n",
    "\n",
    "for response in responses:\n",
    "    num_chunks = len(response.chunks) if response.chunks else 0\n",
    "    hotkey_str = response.axon.hotkey[:10] if response.axon.hotkey else \"No hotkey found\"\n",
    "    process_time = response.dendrite.process_time if response.dendrite.process_time else \"No process time found\"\n",
    "    \n",
    "    print(f\"Received {num_chunks} chunks from hotkey: {hotkey_str}, process time: {process_time}\")    \n",
    "\n",
    "    if not response.chunks:\n",
    "        rewards.append(0)\n",
    "        extra_info_dicts.append({})\n",
    "        continue\n",
    "    reward_value, extra_info_dict = reward(self=None, document=synapse.document, chunk_size=synapse.chunk_size, chunk_qty=synapse.chunk_qty, response=response, override_client=OpenAI(), override_num_embeddings=50, verbose=True)    \n",
    "    rewards.append(reward_value)\n",
    "    extra_info_dicts.append(extra_info_dict)\n",
    "\n",
    "rewards = np.array(rewards)\n",
    "\n",
    "print(f\"Rewards: {rewards}\")\n",
    "\n",
    "response_ranks = rank_responses(rewards)\n",
    "\n",
    "print(f\"Response ranks: {response_ranks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+--------------------+----------------+\n",
      "|   UID |   Embedding reward |   Size penalty |   Quantity penalty |   Time Penalty |\n",
      "+=======+====================+================+====================+================+\n",
      "|    18 |          0.0134873 |              0 |                  0 |              0 |\n",
      "+-------+--------------------+----------------+--------------------+----------------+\n",
      "|   116 |          0.0134873 |              0 |                  0 |              0 |\n",
      "+-------+--------------------+----------------+--------------------+----------------+\n",
      "|    13 |          0.0134984 |              0 |                  0 |              0 |\n",
      "+-------+--------------------+----------------+--------------------+----------------+\n",
      "|   100 |          0.0134711 |              0 |                  0 |              0 |\n",
      "+-------+--------------------+----------------+--------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print_extra_info_dict(extra_info_dicts, top_4_miners_uids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These response ranks would then be translated into global ranks (no change in this case as they are the top 4 miners) and combined with the previous `scores` as a moving average (therefore a lower `score` is better, even if a higher `reward` is better). \n",
    "\n",
    "Weights are then determined based on the global `scores` (which is basically just ranks as a moving average for all miner UIDs)\n",
    "\n",
    "So, if the ranks are [2, 0, 3, 1] (0-indexed):\n",
    "- the old scores might be something like [2.0393, 0.55, 2.539, 1.3940] (as it is the moving average of ranks)\n",
    "- the new scores might be something like [2.0373, 0.5225, 2.562, 1.3742] (with an `alpha` of 0.05)\n",
    "    - the moving average calculation is:\n",
    "    ```py\n",
    "    new_score = global_rank * alpha + old_score * (1 - alpha)\n",
    "    ```\n",
    "- the weights would be [0.25, 1, 0.125, 0.5], where each index is a UID."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
